{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "#    2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "#    3. month - month of the year: \"jan\" to \"dec\" \n",
    "#    4. day - day of the week: \"mon\" to \"sun\"\n",
    "#    5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "#    6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "#    7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "#    8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "#    9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "#    10. RH - relative humidity in %: 15.0 to 100\n",
    "#    11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    "#    12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "#    13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    "#    (this output variable is very skewed towards 0.0, thus it may make\n",
    "#     sense to model with the logarithm transform). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset --------------------------------\n",
      "[['7' '5' 'mar' 'fri' '86.2' '26.2' '94.3' '5.1' '8.2' '51' '6.7' '0']\n",
      " ['7' '4' 'oct' 'tue' '90.6' '35.4' '669.1' '6.7' '18' '33' '0.9' '0']\n",
      " ['7' '4' 'oct' 'sat' '90.6' '43.7' '686.9' '6.7' '14.6' '33' '1.3' '0']\n",
      " ['8' '6' 'mar' 'fri' '91.7' '33.3' '77.5' '9' '8.3' '97' '4' '0.2']\n",
      " ['8' '6' 'mar' 'sun' '89.3' '51.3' '102.2' '9.6' '11.4' '99' '1.8' '0']] \n",
      "\n",
      "{'apr': 3, 'dec': 11, 'jul': 6, 'may': 4, 'nov': 10, 'oct': 9, 'jun': 5, 'mar': 2, 'sep': 8, 'jan': 0, 'aug': 7, 'feb': 1}\n",
      "['mar' 'oct' 'oct' 'mar' 'mar']\n",
      "[2 9 9 2 2] \n",
      "\n",
      "{'thu': 3, 'sat': 5, 'wed': 2, 'mon': 0, 'fri': 4, 'tue': 1, 'sun': 6}\n",
      "['fri' 'tue' 'sat' 'fri' 'sun']\n",
      "[4 1 5 4 6] \n",
      "\n",
      "Encoded dataset --------------------------------\n",
      "[[7.000e+00 5.000e+00 2.000e+00 4.000e+00 8.620e+01 2.620e+01 9.430e+01\n",
      "  5.100e+00 8.200e+00 5.100e+01 6.700e+00 0.000e+00]\n",
      " [7.000e+00 4.000e+00 9.000e+00 1.000e+00 9.060e+01 3.540e+01 6.691e+02\n",
      "  6.700e+00 1.800e+01 3.300e+01 9.000e-01 0.000e+00]\n",
      " [7.000e+00 4.000e+00 9.000e+00 5.000e+00 9.060e+01 4.370e+01 6.869e+02\n",
      "  6.700e+00 1.460e+01 3.300e+01 1.300e+00 0.000e+00]\n",
      " [8.000e+00 6.000e+00 2.000e+00 4.000e+00 9.170e+01 3.330e+01 7.750e+01\n",
      "  9.000e+00 8.300e+00 9.700e+01 4.000e+00 2.000e-01]\n",
      " [8.000e+00 6.000e+00 2.000e+00 6.000e+00 8.930e+01 5.130e+01 1.022e+02\n",
      "  9.600e+00 1.140e+01 9.900e+01 1.800e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "UCI_dataset = np.loadtxt(\"forestfires.csv\", \n",
    "                         dtype= 'str', skiprows=1, delimiter=',')\n",
    "\n",
    "X = UCI_dataset[:,0:12]\n",
    "Y = UCI_dataset[:,12]\n",
    "Y = Y.astype(np.float32)\n",
    "print(\"Raw dataset --------------------------------\")\n",
    "print(X[0:5,:],\"\\n\")\n",
    "\n",
    "integer_mapMonths = {x: i for i,x in enumerate(['jan','feb','mar','apr','may','jun',\n",
    "                                                'jul','aug','sep','oct','nov','dec'])}\n",
    "encoded_months = np.asarray([integer_mapMonths[word] for word in X[:,2]])\n",
    "print(integer_mapMonths)\n",
    "print(X[0:5,2])\n",
    "print(encoded_months[0:5],\"\\n\")\n",
    "\n",
    "integer_mapDays = {x: i for i,x in enumerate(['mon','tue','wed','thu','fri','sat','sun'])}\n",
    "encoded_days = np.asarray([integer_mapDays[word] for word in X[:,3]])\n",
    "print(integer_mapDays)\n",
    "print(X[0:5,3])\n",
    "print(encoded_days[0:5],\"\\n\")\n",
    "\n",
    "# Overwrite with encoded data\n",
    "X[:,2] = encoded_months\n",
    "X[:,3] = encoded_days\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "print(\"Encoded dataset --------------------------------\")\n",
    "print(X[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 413 , #Test: 104\n",
      "# inputs: 12\n"
     ]
    }
   ],
   "source": [
    "# Shuffles the data before split\n",
    "# Train/Test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "print(\"# Train: {} , #Test: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "print(\"# inputs: {}\".format(X_train.shape[1]))\n",
    "n = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: rbf, d: 3\n",
      "MAE: 8.17975450195922\n",
      "r2: -0.08255301501084689\n",
      "---------------------------------------\n",
      "K: rbf, d: 5\n",
      "MAE: 8.17975450195922\n",
      "r2: -0.08255301501084689\n",
      "---------------------------------------\n",
      "K: rbf, d: 10\n",
      "MAE: 8.17975450195922\n",
      "r2: -0.08255301501084689\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "for k in ['rbf']:\n",
    "    for d in [3,5,10]:\n",
    "        svm_reg = svm.SVR(kernel=k, degree=d, gamma='auto')\n",
    "        svm_reg.fit(X_train,y_train.reshape(-1))\n",
    "\n",
    "        y_pred = svm_reg.predict(X_test)\n",
    "        print(\"K: {}, d: {}\".format(k,d))\n",
    "        print(\"MAE: {}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "        print(\"r2: {}\".format(r2_score(y_test,y_pred)))\n",
    "        print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 10.643935003039214\n",
      "r2: -0.01276858651466628\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SKlearn MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes=(800,800,800,800,800,800),max_iter=10000)\n",
    "\n",
    "NN.fit(X_train,y_train.reshape(-1))\n",
    "y_pred = NN.predict(X_test)\n",
    "\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "print(\"r2: {}\".format(r2_score(y_test,y_pred)))\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbs: 40, wts: distance\n",
      "MAE: 18.116425531972148\n",
      "r2: -0.5483884481426775\n",
      "---------------------------------------\n",
      "nbs: 40, wts: uniform\n",
      "MAE: 18.13751220703125\n",
      "r2: -0.36008360063703293\n",
      "---------------------------------------\n",
      "nbs: 60, wts: distance\n",
      "MAE: 17.042928046138393\n",
      "r2: -0.3401945468104566\n",
      "---------------------------------------\n",
      "nbs: 60, wts: uniform\n",
      "MAE: 16.343730926513672\n",
      "r2: -0.1510375246075648\n",
      "---------------------------------------\n",
      "nbs: 100, wts: distance\n",
      "MAE: 16.91582434009209\n",
      "r2: -0.21806358172576434\n",
      "---------------------------------------\n",
      "nbs: 100, wts: uniform\n",
      "MAE: 16.586637496948242\n",
      "r2: -0.11075568351398624\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "for nbs in [40,60,100]:\n",
    "    for wts in ['distance','uniform']:\n",
    "        K_nn = KNeighborsRegressor(n_neighbors=nbs,\n",
    "                                   weights=wts,\n",
    "                                   n_jobs=6)\n",
    "\n",
    "        K_nn.fit(X_train,y_train.reshape(-1))\n",
    "        y_pred = K_nn.predict(X_test)\n",
    "\n",
    "        print(\"nbs: {}, wts: {}\".format(nbs, wts))\n",
    "        print(\"MAE: {}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "        print(\"r2: {}\".format(r2_score(y_test,y_pred)))\n",
    "        print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 21.18307728162752\n",
      "r2: -9.876313776533166\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = tree.DecisionTreeRegressor(criterion='mae')\n",
    "\n",
    "tree_clf.fit(X_train,y_train.reshape(-1))\n",
    "\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "print(\"r2: {}\".format(r2_score(y_test,y_pred)))\n",
    "print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.02585747414089\n",
      "r2: -0.07900798301634393\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Stacked regressors\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "n = 10000\n",
    "\n",
    "estimators = [K_nn, NN, svm_reg]\n",
    "\n",
    "regStack = StackingRegressor(regressors=estimators,\n",
    "                             meta_regressor=NN)\n",
    "\n",
    "regStack.fit(X_train,y_train.reshape(-1))\n",
    "\n",
    "y_pred = regStack.predict(X_test)\n",
    "\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "print(\"r2: {}\".format(r2_score(y_test,y_pred)))\n",
    "print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
